{"cells":[{"metadata":{"_uuid":"68d558e7-86ba-43a9-b476-bae0d744a663","_cell_guid":"f50813e4-d92d-41e5-ba46-390784b8fcba","trusted":true},"cell_type":"code","source":["import torch\n","import wandb\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from torchsummary import summary\n","from scipy.ndimage.filters import convolve\n","from torch.utils.data import Dataset, DataLoader\n","from skimage import io, transform\n","import pandas as pd\n","import os\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","epochs = 15\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE=50\n","\n","train_dir = './Train'      ## path to train dataset\n","test_dir = './Test'            ## path to test dataset\n","test_csv = '../input/gtsrb-german-traffic-sign/Test.csv'    ## path to test.csv\n","save_dir = './'                                             ## path to directory to store trained models\n","\n","## for creating test dataset\n","class test_dataset(Dataset):\n","\n","    def __init__(self, test_dir, csv_file, transform=None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.data = pd.read_csv(csv_file)\n","        self.root_dir = test_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir,self.data.iloc[idx, -1])\n","        image = io.imread(img_name)\n","        true_lab = self.data.iloc[idx, -2]\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        sample = (image,true_lab)\n","\n","        return sample\n","    \n","\n","class LocalContrastNormalization(object):\n","\n","    def __init__(self, kernel_size=3, mode='constant', cval=0.0):\n","        self.kernel_size = kernel_size\n","        self.mode = mode\n","        self.cval = cval\n","        \n","    def __call__(self, tensor):\n","       \n","        return torch.stack([self.func(torch.tensor(batch)) for batch in tensor.tolist()])\n","        \n","\n","    def func(self, tensor):\n","    \n","        C, H, W = tensor.size()\n","        kernel = np.ones((self.kernel_size, self.kernel_size))\n","        \n","\n","        arr = np.array(tensor)\n","        local_sum_arr = np.array([convolve(arr[c], kernel, mode=self.mode, cval=self.cval)\n","                                  for c in range(C)]) # An array that has shape(C, H, W)\n","                                                      # Each element [c, h, w] is the summation of the values\n","                                                      # in the window that has arr[c,h,w] at the center.\n","        local_avg_arr = local_sum_arr / (self.kernel_size**2) # The tensor of local averages.\n","\n","        arr_square = np.square(arr)\n","        local_sum_arr_square = np.array([convolve(arr_square[c], kernel, mode=self.mode, cval=self.cval)\n","                                  for c in range(C)]) # An array that has shape(C, H, W)\n","                                                      # Each element [c, h, w] is the summation of the values\n","                                                      # in the window that has arr_square[c,h,w] at the center.\n","        local_norm_arr = np.sqrt(local_sum_arr_square) # The tensor of local Euclidean norms.\n","\n","\n","        local_avg_divided_by_norm = local_avg_arr / (1e-8+local_norm_arr)\n","\n","        result_arr = np.minimum(local_avg_arr, local_avg_divided_by_norm)\n","        \n","        return torch.Tensor(result_arr)\n","\n","\n","\n","    def __repr__(self):\n","        return self._class.name_ + '(kernel_size={0}, threshold={1})'.format(self.kernel_size, self.threshold)\n","    \n","    \n","## Model architecture defination\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 200, kernel_size=7, padding=2)\n","        self.max1 = nn.MaxPool2d(2, stride=2)\n","        self.conv2 = nn.Conv2d(200, 250, kernel_size=4, padding=2)\n","        self.max2 = nn.MaxPool2d(2, stride=2)\n","        self.conv3 = nn.Conv2d(250, 350, kernel_size=4, padding=2)\n","        self.max3 = nn.MaxPool2d(2, stride=2)\n","        self.local = LocalContrastNormalization()\n","        self.conv_drop = nn.Dropout2d(p=0.5)\n","        self.fc1 = nn.Linear(350*6*6, 400)\n","        self.fc2 = nn.Linear(400, 43)\n","\n","        # stn1 localizaton net\n","        self.localization1 = nn.Sequential(\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(3, 250, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(250, 250, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","        )\n","\n","        # Regressor for the 3 * 2 affine matrix\n","        self.fc_loc1 = nn.Sequential(\n","            nn.Linear(250 * 6 * 6, 250),\n","            torch.nn.Dropout(0.5),\n","            nn.ReLU(True),\n","            nn.Linear(250, 3 * 2)\n","        )\n","\n","        # Initialize the weights/bias with identity transformation\n","        self.fc_loc1[3].weight.data.zero_()\n","        self.fc_loc1[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n","        \n","         # stn2 localizaton net\n","        self.localization2 = nn.Sequential(\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(200, 150, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(150, 200, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","        )\n","\n","        # Regressor for the 3 * 2 affine matrix\n","        self.fc_loc2 = nn.Sequential(\n","            nn.Linear(200 * 2 * 2, 300),\n","            torch.nn.Dropout(0.5),\n","            nn.ReLU(True),\n","            nn.Linear(300, 3 * 2)\n","        )\n","\n","        # Initialize the weights/bias with identity transformation\n","        self.fc_loc2[3].weight.data.zero_()\n","        self.fc_loc2[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n","        \n","         # stn3 localizaton net\n","        self.localization3 = nn.Sequential(\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(250, 150, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(150, 200, kernel_size=5, padding=2),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","        )\n","\n","        # Regressor for the 3 * 2 affine matrix\n","        self.fc_loc3 = nn.Sequential(\n","            nn.Linear(200 * 1 * 1, 300),\n","            torch.nn.Dropout(0.5),\n","            nn.ReLU(True),\n","            nn.Linear(300, 3 * 2)\n","        )\n","\n","        # Initialize the weights/bias with identity transformation\n","        self.fc_loc3[3].weight.data.zero_()\n","        self.fc_loc3[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n","\n","    # stn1\n","    def stn1(self, x):\n","        xs1 = self.localization1(x)\n","        xs1 = xs1.view(-1, 250 * 6 * 6)\n","        theta1 = self.fc_loc1(xs1)\n","        theta1 = theta1.view(-1, 2, 3)\n","\n","        grid1 = F.affine_grid(theta1, x.size())\n","        x1 = F.grid_sample(x, grid1)\n","\n","        return x1\n","    \n","    # stn2\n","    def stn2(self, x):\n","        xs2 = self.localization2(x)\n","        xs2 = xs2.view(-1, 200 * 2 * 2)\n","        theta2 = self.fc_loc2(xs2)\n","        theta2 = theta2.view(-1, 2, 3)\n","\n","        grid2 = F.affine_grid(theta2, x.size())\n","        x2 = F.grid_sample(x, grid2)\n","\n","        return x2\n","    \n","    # stn3\n","    def stn3(self, x):\n","        xs3 = self.localization3(x)\n","        xs3 = xs3.view(-1, 200 * 1 * 1)\n","        theta3 = self.fc_loc3(xs3)\n","        theta3 = theta3.view(-1, 2, 3)\n","\n","        grid3 = F.affine_grid(theta3, x.size())\n","        x3 = F.grid_sample(x, grid3)\n","\n","        return x3\n","\n","    def forward(self, x):\n","        # transform the input\n","        x = self.stn1(x)\n","        x = self.conv_drop(F.relu(self.conv1(x)))\n","        x = self.max1(x)\n","        x = self.local(x).to(device)\n","        \n","        x = self.stn2(x)\n","        x = self.conv_drop(F.relu(self.conv2(x)))\n","        x = self.max2(x)\n","        x = self.local(x).to(device)\n","        \n","        x = self.stn3(x)\n","        x = self.conv_drop(F.relu(self.conv3(x)))\n","        x = self.max3(x)\n","        x = self.local(x).to(device)\n","        \n","        x = x.view(-1, 350*6*6)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","## transforms for train data\n","trans = transforms.Compose([\n","    transforms.Resize((48,48)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n","])\n","\n","## transforms for test data\n","\n","test_trans = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((48,48)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n","])\n","\n","tr_data = datasets.ImageFolder(train_dir,transform = trans)\n","train_data_loader = data.DataLoader(tr_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_data = test_dataset(test_dir,test_csv,transform = test_trans)\n","test_data_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n","\n","model = Net().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n","\n","def train(dataloader, model, criterion, optimizer):\n","    size = len(dataloader.dataset)\n","    preds=[]\n","    true=[]\n","    tot_loss=0\n","    \n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X)\n","        loss = criterion(pred, y)\n","        tot_loss += loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        z = F.softmax(pred,dim=1)\n","        z = torch.argmax(z,dim=1)\n","        preds += z.tolist()\n","        true += y.tolist()\n","\n","        if batch % 100 == 0:\n","            print('batch : {} = loss : {}'.format(batch+1,loss.item()))\n","    \n","    accuracy = accuracy_score(true,preds)\n","    tot_loss = tot_loss/(batch+1)     \n","    return (tot_loss,accuracy)\n","\n","def test(dataloader, model):\n","    size = len(dataloader.dataset)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    preds=[]\n","    true=[]\n","    with torch.no_grad():\n","        for batch,data in enumerate(test_data_loader):\n","            X = data[0].to(device)\n","            y = data[1].to(device)\n","            pred = model(X)\n","            test_loss += criterion(pred, y).item()\n","            z = F.softmax(pred,dim=1)\n","            z = torch.argmax(z,dim=1)\n","            preds += z.tolist()\n","            true += y.tolist()\n","            \n","    test_accuracy = accuracy_score(true,preds)\n","    test_loss /= (batch+1)\n","    return (test_loss,test_accuracy)\n","\n","## Training......................\n","\n","epoch_loss=[]\n","acc_list=[]\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loss,train_accuracy = train(train_data_loader, model, criterion, optimizer)\n","    \n","    print('accuracy : {}'.format(100*train_accuracy))\n","    print('epoch loss : {}'.format(train_loss))\n","    \n","    test_loss,test_accuracy = test(test_data_loader, model)\n","    epoch_loss.append({'train loss':train_loss,'test loss':test_loss})\n","    acc_list.append({'train acc':train_accuracy,'test acc':test_accuracy})\n","     \n","    print(f\"Test Error: \\n Accuracy: {(100*test_accuracy):>0.1f}, Avg loss: {test_loss:>8f} \\n\")\n","    torch.save(model, os.path.join(save_dir,f'model_ep{t+1}.pt'))\n","\n","print(\"Training Done!\")"],"execution_count":9,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/gtsrb-german-traffic-sign/Train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-180108257e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m ])\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m \u001b[0mtr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     ):\n\u001b[0;32m--> 253\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    254\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    124\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    125\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/gtsrb-german-traffic-sign/Train'"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit","metadata":{"interpreter":{"hash":"082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"}}},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}